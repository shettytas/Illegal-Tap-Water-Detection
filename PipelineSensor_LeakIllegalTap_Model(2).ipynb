{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9720797-3f1c-49ba-9c14-872a0a7b52c6",
   "metadata": {},
   "source": [
    "# Illegal Tap Water Detection Using Pipeline Sensor Data\n",
    "To build a machine learning model that detects water theft through illegal pipeline taps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b84b71-d2e6-411f-8d4c-d55ae49d2670",
   "metadata": {},
   "source": [
    "## Overview of Dataset\n",
    "This section gives a brief overview of the dataset, including its columns and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e6360e-72d6-471e-b76f-4ade302d704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>SensorID</th>\n",
       "      <th>pressure</th>\n",
       "      <th>flow_rate</th>\n",
       "      <th>leak_intensity</th>\n",
       "      <th>illegal_tap_flag</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.82</td>\n",
       "      <td>123.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:10 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.71</td>\n",
       "      <td>113.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:20 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.84</td>\n",
       "      <td>121.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:30 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.82</td>\n",
       "      <td>121.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.75</td>\n",
       "      <td>121.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time SensorID  pressure  flow_rate  leak_intensity  illegal_tap_flag  \\\n",
       "0  1:00 PM     S001      2.82     123.91             0.0                 0   \n",
       "1  1:10 PM     S001      2.71     113.40             0.0                 0   \n",
       "2  1:20 PM     S001      2.84     121.48             0.0                 0   \n",
       "3  1:30 PM     S001      2.82     121.73             0.0                 0   \n",
       "4  1:40 PM     S001      2.75     121.16             0.0                 0   \n",
       "\n",
       "  event_type  \n",
       "0     normal  \n",
       "1     normal  \n",
       "2     normal  \n",
       "3     normal  \n",
       "4     normal  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pipeline_sensor_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b393c08-1924-46c2-877e-2eccb00dfa6c",
   "metadata": {},
   "source": [
    "## Handling Categorical Variables: Columns like “SensorID”, “Time” and \"event_type\" need to be encoded numerically\n",
    "Loads the sensor dataset, identifies categorical columns (`SensorID`, `Time`, and `event_type`), and encodes them into numeric values using pandas’ built-in category codes. The encoded data is then saved as a new CSV file (`encoded_pipeline_sensor_data.csv`) for further processing or machine learning.\n",
    "\n",
    "* normal - 5\n",
    "* low_leak - 3\n",
    "* blockage - 0\n",
    "* leak_high - 2\n",
    "* irregular_flow - 1\n",
    "* negative_pressure - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca33f06a-4bec-4455-bdfb-8123a79ad14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                 object\n",
      "SensorID             object\n",
      "pressure            float64\n",
      "flow_rate           float64\n",
      "leak_intensity      float64\n",
      "illegal_tap_flag      int64\n",
      "event_type           object\n",
      "dtype: object\n",
      "  SensorID  SensorID_encoded\n",
      "0     S001                 0\n",
      "1     S001                 0\n",
      "2     S001                 0\n",
      "3     S001                 0\n",
      "4     S001                 0\n",
      "  event_type  event_type_encoded\n",
      "0     normal                   5\n",
      "1     normal                   5\n",
      "2     normal                   5\n",
      "3     normal                   5\n",
      "4     normal                   5\n",
      "      Time  Time_encoded\n",
      "0  1:00 PM             0\n",
      "1  1:10 PM             1\n",
      "2  1:20 PM             2\n",
      "3  1:30 PM             3\n",
      "4  1:40 PM             4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>SensorID</th>\n",
       "      <th>pressure</th>\n",
       "      <th>flow_rate</th>\n",
       "      <th>leak_intensity</th>\n",
       "      <th>illegal_tap_flag</th>\n",
       "      <th>event_type</th>\n",
       "      <th>SensorID_encoded</th>\n",
       "      <th>event_type_encoded</th>\n",
       "      <th>Time_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.82</td>\n",
       "      <td>123.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:10 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.71</td>\n",
       "      <td>113.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:20 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.84</td>\n",
       "      <td>121.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:30 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.82</td>\n",
       "      <td>121.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>S001</td>\n",
       "      <td>2.75</td>\n",
       "      <td>121.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time SensorID  pressure  flow_rate  leak_intensity  illegal_tap_flag  \\\n",
       "0  1:00 PM     S001      2.82     123.91             0.0                 0   \n",
       "1  1:10 PM     S001      2.71     113.40             0.0                 0   \n",
       "2  1:20 PM     S001      2.84     121.48             0.0                 0   \n",
       "3  1:30 PM     S001      2.82     121.73             0.0                 0   \n",
       "4  1:40 PM     S001      2.75     121.16             0.0                 0   \n",
       "\n",
       "  event_type  SensorID_encoded  event_type_encoded  Time_encoded  \n",
       "0     normal                 0                   5             0  \n",
       "1     normal                 0                   5             1  \n",
       "2     normal                 0                   5             2  \n",
       "3     normal                 0                   5             3  \n",
       "4     normal                 0                   5             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pipeline_sensor_data.csv')\n",
    "print(df.dtypes)\n",
    "\n",
    "df['SensorID_encoded'] = df['SensorID'].astype('category').cat.codes\n",
    "print(df[['SensorID', 'SensorID_encoded']].head())\n",
    "\n",
    "df['event_type_encoded'] = df['event_type'].astype('category').cat.codes\n",
    "print(df[['event_type', 'event_type_encoded']].head())\n",
    "\n",
    "df['Time_encoded'] = df['Time'].astype('category').cat.codes\n",
    "print(df[['Time', 'Time_encoded']].head())\n",
    "\n",
    "df.to_csv('encoded_pipeline_sensor_data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ac26f-b458-4657-a067-fdc471002edd",
   "metadata": {},
   "source": [
    "## Splitting Dataset by Sensor Segments for Train and Test\n",
    "The dataset is split into training and testing sets based on sensor arguements. We are randomly choosing 80% of them for training and 20% for testing. This helps make sure the model is tested on new sensors it hasn’t seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07bff6d1-26f4-4cf6-b72f-57ff8d4172eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train segments: 160, data points: 8000\n",
      "Test segments: 40, data points: 2000\n",
      "Train class distribution:\n",
      "event_type_encoded\n",
      "1    0.012125\n",
      "2    0.017250\n",
      "3    0.008250\n",
      "4    0.006125\n",
      "5    0.956250\n",
      "Name: proportion, dtype: float64\n",
      "Test class distribution:\n",
      "event_type_encoded\n",
      "0    0.1420\n",
      "1    0.1820\n",
      "2    0.1095\n",
      "3    0.0995\n",
      "4    0.0230\n",
      "5    0.4440\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('encoded_pipeline_sensor_data.csv')\n",
    "\n",
    "# Get unique segments\n",
    "unique_segments = df['SensorID'].unique()\n",
    "\n",
    "# Randomly split segments (without stratification)\n",
    "train_segments, test_segments = train_test_split(\n",
    "    unique_segments,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Select full segments for train and test datasets\n",
    "train_df = df[df['SensorID'].isin(train_segments)]\n",
    "test_df = df[df['SensorID'].isin(test_segments)]\n",
    "\n",
    "# Display counts and class distribution\n",
    "print(f'Train segments: {len(train_segments)}, data points: {len(train_df)}')\n",
    "print(f'Test segments: {len(test_segments)}, data points: {len(test_df)}')\n",
    "\n",
    "print('Train class distribution:')\n",
    "print(train_df['event_type_encoded'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print('Test class distribution:')\n",
    "print(test_df['event_type_encoded'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "train_df.to_csv('train_split.csv', index=False)\n",
    "test_df.to_csv('test_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c893e-f9f7-4ba1-90d5-0c4babdafdc2",
   "metadata": {},
   "source": [
    "# Past-based features\n",
    "We make new features from the past readings of each sensor. Instead of looking at just the current pressure and flow rate, we also add information about how these values changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab459c63-4f42-4bc6-ba2d-735d3a5e385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4400, 30) Test: (1600, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ID_COL = 'SensorID_encoded'\n",
    "TIME_COL = 'Time_encoded'\n",
    "SIG_COLS = ['pressure', 'flow_rate']\n",
    "LAGS = [1, 3, 5, 10]\n",
    "ROLL_WINDOWS = [5, 10, 20]\n",
    "EPS = 1e-6\n",
    "\n",
    "def rolling_slope_past_only(values: np.ndarray, window: int) -> np.ndarray:\n",
    "    n = len(values)\n",
    "    out = np.full(n, np.nan)\n",
    "    t = np.arange(window, dtype=float)\n",
    "    t_mean = t.mean()\n",
    "    var_t = ((t - t_mean) ** 2).sum()\n",
    "    if var_t == 0:\n",
    "        return out\n",
    "    for i in range(window - 1, n):\n",
    "        w = values[i - window + 1 : i + 1]\n",
    "        if np.isnan(w).any():\n",
    "            continue\n",
    "        x_mean = w.mean()\n",
    "        cov_tx = ((t - t_mean) * (w - x_mean)).sum()\n",
    "        out[i] = cov_tx / var_t\n",
    "    return out\n",
    "\n",
    "def add_past_only_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values([ID_COL, TIME_COL]).copy()\n",
    "    g = df.groupby(ID_COL, group_keys=False)\n",
    "\n",
    "    # Lags\n",
    "    for s in SIG_COLS:\n",
    "        for L in LAGS:\n",
    "            df[f'{s}_lag{L}'] = g[s].shift(L)\n",
    "\n",
    "    # Delta and percent change from lag1\n",
    "    for s in SIG_COLS:\n",
    "        df[f'{s}_delta1'] = df[s] - df[f'{s}_lag1']\n",
    "        df[f'{s}_pct1'] = df[f'{s}_delta1'] / (np.abs(df[f'{s}_lag1']) + EPS)\n",
    "\n",
    "    # Rolling stats (past-only)\n",
    "    for s in SIG_COLS:\n",
    "        s_past = g[s].shift(1)\n",
    "        for w in ROLL_WINDOWS:\n",
    "            roll = s_past.groupby(df[ID_COL]).rolling(window=w, min_periods=w)\n",
    "            df[f'{s}_roll{w}_mean'] = roll.mean().reset_index(level=0, drop=True)\n",
    "            df[f'{s}_roll{w}_std']  = roll.std().reset_index(level=0, drop=True)\n",
    "            df[f'{s}_roll{w}_min']  = roll.min().reset_index(level=0, drop=True)\n",
    "            df[f'{s}_roll{w}_max']  = roll.max().reset_index(level=0, drop=True)\n",
    "            df[f'{s}_roll{w}_med']  = roll.median().reset_index(level=0, drop=True)\n",
    "\n",
    "    # Rolling slopes (past-only)\n",
    "    for s in SIG_COLS:\n",
    "        s_past = g[s].shift(1)\n",
    "        arr = s_past.to_numpy()\n",
    "        for w in ROLL_WINDOWS:\n",
    "            col = f'{s}_roll{w}_slope'\n",
    "            df[col] = np.nan\n",
    "            for _, idx in g.indices.items():\n",
    "                idx = np.array(idx)\n",
    "                sl = rolling_slope_past_only(arr[idx], w)\n",
    "                df.loc[idx, col] = sl\n",
    "\n",
    "    # Simple interaction\n",
    "    df['ratio_flow_pressure'] = df['flow_rate_lag1'] / (np.abs(df['pressure_lag1']) + EPS)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Build features on the entire df first\n",
    "df_feat = add_past_only_features(df)\n",
    "\n",
    "# Drop rows without enough history\n",
    "df_feat = df_feat.dropna().reset_index(drop=True)\n",
    "\n",
    "# Recreate the same time-aware mask on df_feat\n",
    "df_feat_sorted = df_feat.sort_values([ID_COL, TIME_COL]).reset_index(drop=True)\n",
    "mask_feat = df_feat_sorted.groupby(ID_COL, group_keys=False).apply(\n",
    "    lambda g: pd.Series([True]*int(len(g)*0.75) + [False]*(len(g)-int(len(g)*0.75)), index=g.index)\n",
    ")\n",
    "\n",
    "# Define features to use in X\n",
    "FEATURE_COLS = (\n",
    "    ['pressure','flow_rate','leak_intensity','illegal_tap_flag','SensorID_encoded','ratio_flow_pressure'] +\n",
    "    [f'pressure_lag{k}' for k in LAGS] + [f'flow_rate_lag{k}' for k in LAGS] +\n",
    "    ['pressure_delta1','pressure_pct1','flow_rate_delta1','flow_rate_pct1'] +\n",
    "    ['pressure_roll5_mean','pressure_roll10_std','pressure_roll20_min',\n",
    "     'flow_rate_roll5_mean','flow_rate_roll10_std','flow_rate_roll20_min',\n",
    "     'pressure_roll5_slope','pressure_roll10_slope','pressure_roll20_slope',\n",
    "     'flow_rate_roll5_slope','flow_rate_roll10_slope','flow_rate_roll20_slope']\n",
    ")\n",
    "\n",
    "X_all = df_feat_sorted[FEATURE_COLS].copy()\n",
    "y_all = df_feat_sorted['event_type_encoded'].copy()\n",
    "\n",
    "X_train, X_test = X_all[mask_feat.values], X_all[~mask_feat.values]\n",
    "y_train, y_test = y_all[mask_feat.values], y_all[~mask_feat.values]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952971fb-51ae-436e-a2e4-751d6b5e7d7c",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We train an XGBoost model to predict the type of pipeline event (for example, normal flow, leakage, or illegal tap) using the sensor data. We read the pre-split training and testing datasets and then use key sensor readings (`pressure`, `flow_rate`, `leak_intensity`, etc.) to predict the column `event_type_encoded`. We also handle class imbalance by giving rare classes more importance during training. The classification report (precision, recall, F1-score). The confusion matrix, which shows how often each class was confused with others. Finally, we map the numeric predictions back to their original event type names to make the results easier to understand.\n",
    "\n",
    "This gives us a clear view of how well the model can detect different types of pipeline events from the sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfa6543b-0c70-44a5-925a-d551b027b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       284\n",
      "           1       0.55      0.97      0.71       364\n",
      "           2       0.96      1.00      0.98       219\n",
      "           3       1.00      0.99      0.99       199\n",
      "           4       0.96      1.00      0.98        46\n",
      "           5       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.74      0.83      0.78      2000\n",
      "weighted avg       0.77      0.85      0.80      2000\n",
      "\n",
      "[[  0 284   0   0   0   0]\n",
      " [  0 354   8   0   2   0]\n",
      " [  0   0 219   0   0   0]\n",
      " [  0   0   2 197   0   0]\n",
      " [  0   0   0   0  46   0]\n",
      " [  0   0   0   0   0 888]]\n",
      "Actual : ['normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal']\n",
      "Predicted: ['normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. LOAD TRAIN/TEST SPLIT FROM CSV\n",
    "train_df = pd.read_csv('train_split.csv')\n",
    "test_df = pd.read_csv('test_split.csv')\n",
    "\n",
    "# 2. DEFINE FEATURES & TARGET\n",
    "feature_cols = ['pressure', 'flow_rate', 'leak_intensity', 'illegal_tap_flag', 'SensorID_encoded', 'Time_encoded']\n",
    "target_col = 'event_type_encoded'\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# 3. FIX LABEL ENCODING SO XGBOOST DOESN'T ERROR\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y_train) + list(y_test))\n",
    "y_train_clean = le.transform(y_train)\n",
    "y_test_clean = le.transform(y_test)\n",
    "\n",
    "# 4. COMPUTE SAMPLE WEIGHTS FOR CLASS IMBALANCE\n",
    "classes = np.unique(y_train_clean)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train_clean)\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "weights = pd.Series(y_train_clean).map(weight_dict)\n",
    "\n",
    "# 5. CREATE DMATRIX FOR XGBOOST\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_clean, weight=weights)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test_clean)\n",
    "\n",
    "# 6. TRAIN XGBOOST MULTI-CLASS MODEL\n",
    "params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(le.classes_),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 42\n",
    "}\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# 7. EVALUATE\n",
    "y_pred_prob = bst.predict(dtest)\n",
    "y_pred = y_pred_prob.argmax(axis=1)\n",
    "print(classification_report(y_test_clean, y_pred))\n",
    "print(confusion_matrix(y_test_clean, y_pred))\n",
    "\n",
    "# Create mapping from encoded labels to human-readable event types\n",
    "#mapping = dict(zip(train_df['event_type_encoded'], train_df['event_type']))\n",
    "# Combine train and test to ensure all event types are covered\n",
    "all_labels = pd.concat([\n",
    "    train_df[['event_type_encoded', 'event_type']],\n",
    "    test_df[['event_type_encoded', 'event_type']]\n",
    "]).drop_duplicates()\n",
    "\n",
    "mapping = dict(zip(all_labels['event_type_encoded'], all_labels['event_type']))\n",
    "\n",
    "# Convert numeric predictions and actuals back to human-readable labels\n",
    "actual_event_types = [mapping[x] for x in y_test_clean]\n",
    "predicted_event_types = [mapping[x] for x in y_pred]\n",
    "\n",
    "# Show first 10 results\n",
    "print(\"Actual :\", actual_event_types[:20])\n",
    "print(\"Predicted:\", predicted_event_types[:20])\n",
    "# This converts the numeric codes back to original event type strings\n",
    "predicted_labels = le.inverse_transform(y_pred)\n",
    "actual_labels = le.inverse_transform(y_test_clean)\n",
    "\n",
    "# Save model\n",
    "bst.save_model(\"xgboost_pipeline_event_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ae030-ccb0-48d7-bb9b-58fbf257eece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bac5c-fc85-48c2-9703-2df88381ef5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
